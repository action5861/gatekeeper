# services/website-analysis-service/main.py
import os
import json
import logging
from typing import Any, cast

from fastapi import FastAPI, BackgroundTasks, HTTPException
from pydantic import BaseModel
from playwright.async_api import async_playwright  # type: ignore
from bs4 import BeautifulSoup  # type: ignore

# Gemini SDK (pyrightê°€ ì´ ê²½ë¡œë¥¼ ë” ì˜ ì¸ì‹)
from google import generativeai as genai  # type: ignore

# ì•ˆì „ì„¤ì • enum (ë²„ì „ì— ë”°ë¼ ì—†ì„ ìˆ˜ ìˆì–´ try/except)
try:
    from google.generativeai.types import HarmCategory, HarmBlockThreshold  # type: ignore
except Exception:
    HarmCategory = None  # type: ignore[assignment]
    HarmBlockThreshold = None  # type: ignore[assignment]

# Database
from database import database, connect_to_database, disconnect_from_database

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# --- í™˜ê²½ ë³€ìˆ˜ ë° ëª¨ë¸ ì„¤ì • ---
API_KEY = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY") or ""
MODEL_NAME = os.getenv("GEMINI_MODEL", "models/gemini-flash-latest")

if not API_KEY.strip():
    raise RuntimeError("GEMINI_API_KEY/GOOGLE_API_KEY ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

genai.configure(api_key=API_KEY)  # type: ignore[attr-defined]
model: Any = cast(Any, genai).GenerativeModel(MODEL_NAME)  # type: ignore[attr-defined]

app = FastAPI()


# --- Pydantic ëª¨ë¸ ---
class AnalysisRequest(BaseModel):
    advertiser_id: int
    url: str


# --- ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ---
@app.on_event("startup")
async def startup():
    await connect_to_database()
    logger.info("âœ… Website Analysis Service started successfully")
    logger.info(f"[Gemini] KEY_SET={bool(API_KEY)}, MODEL={MODEL_NAME}")


@app.on_event("shutdown")
async def shutdown():
    await disconnect_from_database()


# --- í•µì‹¬ ë¡œì§ ---
async def scrape_website_text(url: str) -> str:
    """
    Playwrightë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ì‚¬ì´íŠ¸ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤.
    networkidle íƒ€ì„ì•„ì›ƒ ì‹œ domcontentloadedë¡œ í´ë°±í•©ë‹ˆë‹¤.
    """
    async with async_playwright() as p:
        browser = await p.chromium.launch()
        page = await browser.new_page()
        try:
            # 1ì°¨ ì‹œë„: networkidle (ìµœëŒ€ 60ì´ˆ)
            try:
                await page.goto(url, wait_until="networkidle", timeout=60000)
                logger.info(f"âœ… networkidleë¡œ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ: {url}")
            except Exception as e:
                logger.warning(f"âš ï¸ networkidle íƒ€ì„ì•„ì›ƒ, domcontentloadedë¡œ ì¬ì‹œë„: {url} - {str(e)}")
                # 2ì°¨ ì‹œë„: domcontentloaded (ìµœëŒ€ 30ì´ˆ)
                try:
                    await page.goto(url, wait_until="domcontentloaded", timeout=30000)
                    logger.info(f"âœ… domcontentloadedë¡œ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ: {url}")
                    # ì¶”ê°€ ëŒ€ê¸°: JavaScript ì‹¤í–‰ì„ ìœ„í•´ 3ì´ˆ ëŒ€ê¸°
                    await page.wait_for_timeout(3000)
                except Exception as e2:
                    logger.warning(f"âš ï¸ domcontentloadedë„ ì‹¤íŒ¨, loadë¡œ ì¬ì‹œë„: {url} - {str(e2)}")
                    # 3ì°¨ ì‹œë„: load (ìµœëŒ€ 30ì´ˆ)
                    try:
                        await page.goto(url, wait_until="load", timeout=30000)
                        logger.info(f"âœ… loadë¡œ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ: {url}")
                        # ì¶”ê°€ ëŒ€ê¸°: JavaScript ì‹¤í–‰ì„ ìœ„í•´ 2ì´ˆ ëŒ€ê¸°
                        await page.wait_for_timeout(2000)
                    except Exception as e3:
                        logger.error(f"âŒ ëª¨ë“  ë¡œë“œ ì „ëµ ì‹¤íŒ¨: {url} - {str(e3)}")
                        # ë§ˆì§€ë§‰ ì‹œë„: íƒ€ì„ì•„ì›ƒ ì—†ì´ ìµœì†Œí•œì˜ ì½˜í…ì¸ ë¼ë„ ê°€ì ¸ì˜¤ê¸°
                        try:
                            await page.goto(url, wait_until="commit", timeout=10000)
                            await page.wait_for_timeout(5000)  # 5ì´ˆ ëŒ€ê¸°
                            logger.info(f"âš ï¸ commitìœ¼ë¡œ ìµœì†Œ ì½˜í…ì¸  ë¡œë“œ: {url}")
                        except Exception as e4:
                            logger.error(f"âŒ ìµœì¢… ë¡œë“œ ì‹¤íŒ¨: {url} - {str(e4)}")
                            return ""
            
            html_content = await page.content()
            soup = BeautifulSoup(html_content, "html.parser")
            # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
            for tag in soup(["script", "style", "nav", "footer", "header"]):
                tag.decompose()
            text = soup.get_text(separator=" ", strip=True)
            # ìµœëŒ€ 15000ìë¡œ ì œí•œ
            result = " ".join(text.split())[:15000]
            logger.info(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(result)}ì")
            return result
        except Exception as e:
            logger.error(f"âŒ ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {url} - {str(e)}", exc_info=True)
            return ""
        finally:
            await browser.close()


async def analyze_with_gemini(text_content: str) -> dict:
    """
    Gemini AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    prompt = f"""
ë‹¹ì‹ ì€ ìµœê³ ì˜ ë””ì§€í„¸ ë§ˆì¼€íŒ… ì „ëµê°€ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” í•œ ê¸°ì—…ì˜ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ ë°ì´í„°ì…ë‹ˆë‹¤.
ì´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ì˜ JSON ê°ì²´ë¥¼ ë°˜ë“œì‹œ ìƒì„±í•´ì£¼ì„¸ìš”:

{{
    "business_summary": "100ì ì´ë‚´ë¡œ ë¹„ì¦ˆë‹ˆìŠ¤ë¥¼ ìš”ì•½í•œ í…ìŠ¤íŠ¸",
    "recommended_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", ...],
    "recommended_categories": ["ì¹´í…Œê³ ë¦¬1", "ì¹´í…Œê³ ë¦¬2", ...]
}}

**ì¤‘ìš” ì§€ì‹œì‚¬í•­:**
1. business_summaryëŠ” ë°˜ë“œì‹œ 100ì ì´ë‚´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
2. recommended_keywordsëŠ” ìµœì†Œ 10ê°œ ì´ìƒ, ìµœëŒ€ 20ê°œê¹Œì§€ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”. ë¹„ì¦ˆë‹ˆìŠ¤ì™€ ê´€ë ¨ëœ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì œì‹œí•˜ì„¸ìš”.
3. recommended_categoriesëŠ” ìµœì†Œ 3ê°œ ì´ìƒ, ìµœëŒ€ 5ê°œê¹Œì§€ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”. ë¹„ì¦ˆë‹ˆìŠ¤ ì¹´í…Œê³ ë¦¬ ê²½ë¡œë¥¼ ì œì‹œí•˜ì„¸ìš”.
4. JSON í˜•ì‹ë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì½”ë“œë¸”ë¡(```), ì„¤ëª…, ì¶”ê°€ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
5. í‚¤ì›Œë“œì™€ ì¹´í…Œê³ ë¦¬ëŠ” ë¹„ì–´ìˆëŠ” ë°°ì—´ì´ë©´ ì•ˆ ë©ë‹ˆë‹¤. ë°˜ë“œì‹œ ê°’ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

---
ì›¹ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸:
{text_content[:5000]}
---
"""

    # safety_settings: ë²„ì „ í˜¸í™˜ì„ ìœ„í•´ list[dict] í˜•íƒœ ê¶Œì¥
    safety_settings = None
    if HarmCategory and HarmBlockThreshold:
        safety_settings = [
            {"category": HarmCategory.HARM_CATEGORY_HARASSMENT, "threshold": HarmBlockThreshold.BLOCK_NONE},  # type: ignore[attr-defined]
            {"category": HarmCategory.HARM_CATEGORY_HATE_SPEECH, "threshold": HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE},  # type: ignore[attr-defined]
            {"category": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, "threshold": HarmBlockThreshold.BLOCK_NONE},  # type: ignore[attr-defined]
            {"category": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, "threshold": HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE},  # type: ignore[attr-defined]
        ]

    try:
        responder = getattr(model, "generate_content_async", None)
        if callable(responder):
            response = await model.generate_content_async(prompt, safety_settings=safety_settings)  # type: ignore[attr-defined]
        else:
            response = model.generate_content(prompt, safety_settings=safety_settings)  # type: ignore[attr-defined]

        text = getattr(response, "text", "") or ""
        if not text.strip():
            # candidates ê¸°ë°˜ ë°©ì–´
            candidates = getattr(response, "candidates", []) or []
            for c in candidates:
                content = getattr(c, "content", None)
                parts = getattr(content, "parts", []) if content else []
                if parts and hasattr(parts[0], "text"):
                    text = parts[0].text or ""
                    if text.strip():
                        break

        if not text.strip():
            logger.error("âŒ Gemini ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return {}

        raw = text.strip()
        try:
            result = json.loads(raw)
        except json.JSONDecodeError:
            start, end = raw.find("{"), raw.rfind("}")
            if start != -1 and end != -1 and end > start:
                result = json.loads(raw[start : end + 1])
            else:
                raise

        # ìœ íš¨ì„± ë³´ì • + ê°œìˆ˜ ì œí•œ
        result.setdefault("business_summary", "AI ë¶„ì„ ìš”ì•½ ì—†ìŒ")
        result.setdefault("recommended_keywords", [])
        result.setdefault("recommended_categories", [])
        result["recommended_keywords"] = result["recommended_keywords"][:20]
        result["recommended_categories"] = result["recommended_categories"][:5]
        
        # ë¡œê¹…: Gemini ì‘ë‹µ í™•ì¸
        logger.info(f"ğŸ¤– Gemini ë¶„ì„ ê²°ê³¼: summary={len(result.get('business_summary', ''))}ì, keywords={len(result.get('recommended_keywords', []))}ê°œ, categories={len(result.get('recommended_categories', []))}ê°œ")
        logger.info(f"ğŸ¤– í‚¤ì›Œë“œ ìƒ˜í”Œ: {result.get('recommended_keywords', [])[:5]}")
        logger.info(f"ğŸ¤– ì¹´í…Œê³ ë¦¬ ìƒ˜í”Œ: {result.get('recommended_categories', [])[:3]}")
        
        return result

    except Exception as e:
        logger.error(f"âŒ Error calling/parsing Gemini API: {e}", exc_info=True)
        return {}


async def save_analysis_results(advertiser_id: int, results: dict):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ’¾ [{advertiser_id}] ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹œì‘")
    logger.info(f"ğŸ’¾ [{advertiser_id}] results keys: {list(results.keys())}")
    
    summary = results.get("business_summary", "AI ë¶„ì„ ìš”ì•½ ì—†ìŒ")
    logger.info(f"ğŸ’¾ [{advertiser_id}] summary: {summary[:100]}...")
    
    await database.execute(
        "UPDATE advertiser_reviews SET website_analysis = :summary, review_status = 'pending' WHERE advertiser_id = :advertiser_id",
        {"summary": summary, "advertiser_id": advertiser_id},
    )

    keywords = results.get("recommended_keywords", [])
    logger.info(f"ğŸ’¾ [{advertiser_id}] í‚¤ì›Œë“œ ê°œìˆ˜: {len(keywords)}, í‚¤ì›Œë“œ: {keywords}")
    
    keyword_count = 0
    for keyword in keywords:
        if keyword and isinstance(keyword, str) and keyword.strip():
            await database.execute(
                """
                INSERT INTO advertiser_keywords (advertiser_id, keyword, source, match_type, priority)
                VALUES (:advertiser_id, :keyword, 'ai_suggested', 'broad', 1)
                """,
                {"advertiser_id": advertiser_id, "keyword": keyword.strip()},
            )
            keyword_count += 1
    
    logger.info(f"ğŸ’¾ [{advertiser_id}] ì €ì¥ëœ í‚¤ì›Œë“œ ê°œìˆ˜: {keyword_count}")

    categories = results.get("recommended_categories", [])
    logger.info(f"ğŸ’¾ [{advertiser_id}] ì¹´í…Œê³ ë¦¬ ê°œìˆ˜: {len(categories)}, ì¹´í…Œê³ ë¦¬: {categories}")
    
    category_count = 0
    for category in categories:
        if category and isinstance(category, str) and category.strip():
            await database.execute(
                """
                INSERT INTO advertiser_categories (advertiser_id, category_path, source, category_level, is_primary)
                VALUES (:advertiser_id, :category_path, 'ai_suggested', 1, false)
                """,
                {"advertiser_id": advertiser_id, "category_path": category.strip()},
            )
            category_count += 1
    
    logger.info(f"ğŸ’¾ [{advertiser_id}] ì €ì¥ëœ ì¹´í…Œê³ ë¦¬ ê°œìˆ˜: {category_count}")

    await database.execute(
        "UPDATE advertisers SET approval_status = 'pending' WHERE id = :advertiser_id",
        {"advertiser_id": advertiser_id},
    )
    
    logger.info(f"ğŸ’¾ [{advertiser_id}] ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: í‚¤ì›Œë“œ {keyword_count}ê°œ, ì¹´í…Œê³ ë¦¬ {category_count}ê°œ")


async def run_analysis_task(advertiser_id: int, url: str):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë˜ëŠ” ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ íƒœìŠ¤í¬ì…ë‹ˆë‹¤.
    """
    try:
        logger.info(f"ğŸ” [{advertiser_id}] ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ ì‹œì‘: {url}")

        # 1) ìƒíƒœ ë³€ê²½
        await database.execute(
            "UPDATE advertisers SET approval_status = 'pending_analysis' WHERE id = :advertiser_id",
            {"advertiser_id": advertiser_id},
        )

        # 2) ìŠ¤í¬ë˜í•‘
        scraped_text = await scrape_website_text(url)
        if not scraped_text:
            await database.execute(
                "UPDATE advertisers SET approval_status = 'pending' WHERE id = :advertiser_id",
                {"advertiser_id": advertiser_id},
            )
            await database.execute(
                "UPDATE advertiser_reviews SET website_analysis = 'ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ ì‹¤íŒ¨: ì‚¬ì´íŠ¸ ì ‘ê·¼ ë¶ˆê°€', review_status = 'pending' WHERE advertiser_id = :advertiser_id",
                {"advertiser_id": advertiser_id},
            )
            return

        # 3) Gemini ë¶„ì„
        logger.info(f"ğŸ” [{advertiser_id}] Gemini AI ë¶„ì„ ì‹œì‘...")
        analysis_results = await analyze_with_gemini(scraped_text)
        logger.info(f"ğŸ” [{advertiser_id}] Gemini AI ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ í‚¤: {list(analysis_results.keys()) if analysis_results else 'None'}")
        if not analysis_results:
            await database.execute(
                "UPDATE advertisers SET approval_status = 'pending' WHERE id = :advertiser_id",
                {"advertiser_id": advertiser_id},
            )
            await database.execute(
                "UPDATE advertiser_reviews SET website_analysis = 'ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ ì‹¤íŒ¨: AI ë¶„ì„ ì˜¤ë¥˜', review_status = 'pending' WHERE advertiser_id = :advertiser_id",
                {"advertiser_id": advertiser_id},
            )
            return

        # 4) ê²°ê³¼ ì €ì¥
        await save_analysis_results(advertiser_id, analysis_results)
        logger.info(f"âœ¨ [{advertiser_id}] ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")

    except Exception as e:
        logger.error(f"ğŸ’¥ [{advertiser_id}] ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
        try:
            await database.execute(
                "UPDATE advertisers SET approval_status = 'pending' WHERE id = :advertiser_id",
                {"advertiser_id": advertiser_id},
            )
            await database.execute(
                "UPDATE advertiser_reviews SET website_analysis = :analysis, review_status = 'pending' WHERE advertiser_id = :advertiser_id",
                {
                    "analysis": f"ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                    "advertiser_id": advertiser_id,
                },
            )
        except Exception as inner_e:
            logger.error(
                f"ğŸ’¥ [{advertiser_id}] ì—ëŸ¬ ì²˜ë¦¬ ì¤‘ ì¶”ê°€ ì˜ˆì™¸: {inner_e}", exc_info=True
            )


# --- API ì—”ë“œí¬ì¸íŠ¸ ---
@app.post("/analyze")
async def start_analysis(request: AnalysisRequest, background_tasks: BackgroundTasks):
    """
    ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ì„ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹œì‘í•©ë‹ˆë‹¤.
    """
    advertiser = await database.fetch_one(
        "SELECT id, website_url FROM advertisers WHERE id = :advertiser_id",
        {"advertiser_id": request.advertiser_id},
    )
    if not advertiser:
        raise HTTPException(status_code=404, detail="Advertiser not found")

    background_tasks.add_task(run_analysis_task, request.advertiser_id, request.url)
    return {
        "message": "Analysis started in the background.",
        "advertiser_id": request.advertiser_id,
        "url": request.url,
    }


@app.get("/health")
def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "ok", "service": "website-analysis-service"}


@app.get("/status/{advertiser_id}")
async def get_analysis_status(advertiser_id: int):
    """
    íŠ¹ì • ê´‘ê³ ì£¼ì˜ ë¶„ì„ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    advertiser = await database.fetch_one(
        "SELECT id, approval_status FROM advertisers WHERE id = :advertiser_id",
        {"advertiser_id": advertiser_id},
    )
    if not advertiser:
        raise HTTPException(status_code=404, detail="Advertiser not found")

    review = await database.fetch_one(
        "SELECT review_status, website_analysis FROM advertiser_reviews WHERE advertiser_id = :advertiser_id",
        {"advertiser_id": advertiser_id},
    )

    keywords_count = await database.fetch_val(
        "SELECT COUNT(*) FROM advertiser_keywords WHERE advertiser_id = :advertiser_id AND source = 'ai_suggested'",
        {"advertiser_id": advertiser_id},
    )

    categories_count = await database.fetch_val(
        "SELECT COUNT(*) FROM advertiser_categories WHERE advertiser_id = :advertiser_id AND source = 'ai_suggested'",
        {"advertiser_id": advertiser_id},
    )

    return {
        "advertiser_id": advertiser_id,
        "approval_status": advertiser["approval_status"],
        "review_status": review["review_status"] if review else None,
        "website_analysis": review["website_analysis"] if review else None,
        "ai_suggested_keywords": keywords_count or 0,
        "ai_suggested_categories": categories_count or 0,
    }
