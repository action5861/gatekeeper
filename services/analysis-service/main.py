# services/analysis-service/main.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Literal, Optional
import json
import asyncio
from dotenv import load_dotenv

load_dotenv()

from database import database, connect_to_database, disconnect_from_database
from ai_analyzer import (
    analyze_query_with_ai,
    generate_improved_queries,
    AiAnalysisReport,
)
from legacy_analyzer import (
    evaluate_data_value as evaluate_data_value_legacy,
    LegacyQualityReport,
)

app = FastAPI(
    title="AI-Powered Analysis Service",
    description="A service that analyzes search query value using a hybrid AI and rule-based model.",
    version="2.0.0",
)


@app.on_event("startup")
async def startup():
    await connect_to_database()


@app.on_event("shutdown")
async def shutdown():
    await disconnect_from_database()


app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class EvaluateRequest(BaseModel):
    query: str = Field(..., min_length=1, max_length=200)
    user_id: int = Field(..., description="ë¡œê·¸ì¸í•œ ì‚¬ìš©ìžì˜ ID")


class ImprovedQuery(BaseModel):
    """AIê°€ ì œì•ˆí•œ ê°œì„ ëœ ê²€ìƒ‰ì–´"""

    query: str
    reason: str
    score: Optional[int] = None  # ë¹ ë¥¸ í‰ê°€ í›„ ì¶”ê°€
    commercialValue: Optional[str] = None


class FinalQualityReport(BaseModel):
    score: int
    suggestions: List[str]
    keywords: List[str]
    commercialValue: Literal["low", "medium", "high"]
    ai_analysis: Optional[AiAnalysisReport] = None
    needsImprovement: bool = False  # â­ ê°œì„  í•„ìš” í”Œëž˜ê·¸
    aiSuggestions: Optional[List[ImprovedQuery]] = None  # â­ AI ê°œì„  ì œì•ˆ


class EvaluateResponse(BaseModel):
    success: bool
    data: FinalQualityReport
    message: str


def blend_reports(
    legacy_report: LegacyQualityReport, ai_report: Optional[AiAnalysisReport]
) -> FinalQualityReport:
    if not ai_report:
        return FinalQualityReport(**legacy_report.dict())

    final_score = int(
        (
            ai_report.commercial_intent * 100 * 0.5
            + ai_report.specificity_level * 100 * 0.3
        )
        + (legacy_report.score * 0.2)
    )
    final_score = max(10, min(100, final_score))
    if final_score >= 75:
        commercial_value = "high"
    elif final_score >= 45:
        commercial_value = "medium"
    else:
        commercial_value = "low"

    suggestions = []
    if ai_report.specificity_level < 0.4:
        if ai_report.predicted_keywords:
            suggestions.append(
                f"'{ai_report.predicted_keywords[0]}'ì™€ ê°™ì€ êµ¬ì²´ì ì¸ ì œí’ˆëª…ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”."
            )
        else:
            suggestions.append("êµ¬ì²´ì ì¸ ì œí’ˆëª…ì´ë‚˜ ë¸Œëžœë“œë¥¼ í¬í•¨í•´ë³´ì„¸ìš”.")
    if ai_report.buyer_journey_stage == "Consideration":
        suggestions.append(
            "'ë¹„êµ', 'ë¦¬ë·°', 'ì¶”ì²œ'ê³¼ ê°™ì€ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ë©´ ë” ê°€ì¹˜ìžˆëŠ” ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤."
        )
    else:
        suggestions.append("í›Œë¥­í•œ ê²€ìƒ‰ì–´ìž…ë‹ˆë‹¤! ìž ìž¬ì  ê°€ì¹˜ê°€ ë†’ê²Œ í‰ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return FinalQualityReport(
        score=final_score,
        suggestions=suggestions,
        keywords=list(set(legacy_report.keywords + ai_report.predicted_keywords)),
        commercialValue=commercial_value,
        ai_analysis=ai_report,
    )


@app.post("/evaluate", response_model=EvaluateResponse)
async def evaluate_query(request: EvaluateRequest):
    query_text = request.query.strip()

    # AI ë¶„ì„ (ëŠë¦¼: ~5ì´ˆ)ê³¼ Legacy ë¶„ì„ (ë¹ ë¦„: ~0.1ì´ˆ)ì„ ë™ì‹œ ì‹œìž‘
    ai_task = asyncio.create_task(analyze_query_with_ai(query_text))
    legacy_task = asyncio.to_thread(evaluate_data_value_legacy, query_text)

    # LegacyëŠ” ë°˜ë“œì‹œ ê¸°ë‹¤ë¦¼ (ë§¤ìš° ë¹ ë¦„)
    legacy_report = await legacy_task

    # AIëŠ” ì¶©ë¶„í•œ ì‹œê°„(10ì´ˆ)ì„ ì£¼ê³  ê¸°ë‹¤ë¦¼ (í’ˆì§ˆ ìš°ì„ , í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë¡œë”© í‘œì‹œ)
    try:
        ai_report = await asyncio.wait_for(ai_task, timeout=10.0)
        print(f"âœ“ AI ë¶„ì„ ì™„ë£Œ: {query_text[:30]}... (ê³ í’ˆì§ˆ ê²°ê³¼)")
    except asyncio.TimeoutError:
        print(f"âš  AI íƒ€ìž„ì•„ì›ƒ (10ì´ˆ ì´ˆê³¼): {query_text[:30]}... â†’ Legacy ì‚¬ìš©")
        ai_report = None
    except Exception as e:
        print(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: {e} â†’ Legacy ì‚¬ìš©")
        ai_report = None

    final_report = blend_reports(legacy_report, ai_report)

    # â­ 30ì  ë¯¸ë§Œ ë˜ëŠ” low ê°’ì´ë©´ AI ê°œì„  ì œì•ˆ ìƒì„±
    if final_report.score < 30 or final_report.commercialValue == "low":
        print(
            f"ðŸ”„ ì €í’ˆì§ˆ ê²€ìƒ‰ì–´ ê°ì§€ ({final_report.score}ì ) - AI ê°œì„  ì œì•ˆ ìƒì„± ì¤‘..."
        )
        try:
            improved_suggestions = await asyncio.wait_for(
                generate_improved_queries(query_text), timeout=10.0
            )

            if improved_suggestions:
                # ê° ì œì•ˆ ê²€ìƒ‰ì–´ë„ ë¹ ë¥´ê²Œ í‰ê°€ (Legacyë§Œ ì‚¬ìš©)
                evaluated_suggestions = []
                for sugg in improved_suggestions:
                    quick_eval = evaluate_data_value_legacy(sugg["query"])
                    evaluated_suggestions.append(
                        ImprovedQuery(
                            query=sugg["query"],
                            reason=sugg.get("reason", "ê°œì„ ë¨"),
                            score=quick_eval.score,
                            commercialValue=quick_eval.commercialValue,
                        )
                    )

                final_report.needsImprovement = True
                final_report.aiSuggestions = evaluated_suggestions
                print(f"âœ¨ AI ê°œì„  ì œì•ˆ ìƒì„± ì™„ë£Œ: {len(evaluated_suggestions)}ê°œ")
        except Exception as e:
            print(f"âš ï¸ ê°œì„  ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
    db_query = """
        INSERT INTO search_queries (user_id, query_text, quality_score, commercial_value, keywords, suggestions, ai_analysis_data)
        VALUES (:user_id, :query_text, :quality_score, :commercial_value, :keywords, :suggestions, :ai_analysis_data)
    """
    values = {
        "user_id": request.user_id,
        "query_text": query_text,
        "quality_score": final_report.score,
        "commercial_value": final_report.commercialValue,
        "keywords": json.dumps(final_report.keywords),
        "suggestions": json.dumps(final_report.suggestions),
        "ai_analysis_data": (
            final_report.ai_analysis.json() if final_report.ai_analysis else None
        ),
    }
    try:
        await database.execute(db_query, values)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Database error: {e}")

    return EvaluateResponse(
        success=True,
        data=final_report,
        message="AI ê¸°ë°˜ ë°ì´í„° ê°€ì¹˜ í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
    )


@app.get("/health")
async def health_check():
    db_status = "connected" if database.is_connected else "disconnected"
    return {
        "status": "healthy",
        "service": "Analysis Service v2.0",
        "database": db_status,
        "ai_model": "models/gemini-flash-latest",
    }


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8001)
